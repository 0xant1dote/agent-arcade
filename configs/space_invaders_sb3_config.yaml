algo: "DQN"
env: "ALE/SpaceInvaders-v5"

# Increase total timesteps for more thorough learning
total_timesteps: 5000000

# Learning parameters
learning_rate: 0.0001
buffer_size: 100000  # Reduced to fit memory constraints
learning_starts: 50000
batch_size: 128
tau: 0.005
gamma: 0.99
train_freq: 4
gradient_steps: 1
target_update_interval: 1000

# Exploration parameters
exploration_fraction: 0.2  # Slower exploration decay
exploration_initial_eps: 1.0
exploration_final_eps: 0.05  # Higher final exploration for more variety

# Network architecture
policy_kwargs:
  net_arch:
    - 512
    - 256
    - 128
  normalize_images: true

# Environment settings
n_envs: 4  # Reduced number of parallel environments
frame_stack: 4
reward_scale: 1.0

# Training monitoring
train_log_interval: 100
video_interval: 50000  # More frequent video recording

# Preprocessing
grayscale: true
frame_skip: 4
noop_max: 30
episode_life: true
clip_reward: true
screen_size: 84

# Save checkpoints more frequently
checkpoint_freq: 100000
save_path: "models/space_invaders_dqn"

# Evaluation during training
eval_freq: 50000
n_eval_episodes: 10
eval_log_path: "logs/eval"

# Device settings
device: "auto"

# Workshop and visualization settings
viz_interval: 25000
video_length: 400
checkpoint_interval: 100000
demo_mode: false 